{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDS using Random Forest Classifier-Working with Unbalanced Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghimirebimal/ML-Projects/blob/main/IDS_using_Random_Forest_Classifier_Working_with_Unbalanced_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64cZomz_cm3M"
      },
      "source": [
        "# Intrusion Detection System using ML model to predict attacks\n",
        "#### Using KDD dataset to predict attacks correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAZJp7Hdduio"
      },
      "source": [
        "### Learning Objectives\n",
        "* Learn to create and evaluate Intrusion Detection System (IDS) using Random Forest Classifier.\n",
        "* Visualize the predictions made by the algorithm with Confusion Matrix and performance metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SadmPJQbdod1"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Import all the required libraries including pandas, numpy, and matplotlib for the lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVq5JvmUp56g"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "plt.style.use('seaborn-white')\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdNY0JY8jVh5"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "In the code cell below, we mount the google drive to the colab environment so that we have access to the local version of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUeKClB3jkS7"
      },
      "source": [
        "### Read CSV\n",
        "\n",
        "We read the csv file using pandas in the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WulIRz8qqgdI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "984f1480-47e1-4dd4-8889-73e6f456163c"
      },
      "source": [
        "mydata = pd.read_csv('/content/drive/My Drive/Intro2MLDatasets/Lab5/KDDCup99.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cfeb57cf50df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Intro2MLDatasets/Lab5/KDDCup99.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Intro2MLDatasets/Lab5/KDDCup99.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr5E092Ej22Z"
      },
      "source": [
        "### Analyzing Dataset\n",
        "\n",
        "This code allows us to see the length and width of the dataset. The first integer denotes the number of rows and the second integer denotes the number of columns in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2HvhWlHyuuY"
      },
      "source": [
        "mydata.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3hTppBG_1wp"
      },
      "source": [
        "The code cells below help us visualize the dataest in every angle. We use the given functions from pandas to display the shape, first 100 data, and the features in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSll4dCWyyHb"
      },
      "source": [
        "mydata.head(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKJp_aat-2iz"
      },
      "source": [
        "mydata.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhzRjYCckrT4"
      },
      "source": [
        "### Identify Features to drop\n",
        "\n",
        "In the code below, we identify the features which are same in every instances. 'lnum_outbound_cmds' and 'is_host_login' are the two features which has same data in every row of the dataset. Hence, these features will not help model to predict the attacks and are not necessary in the dataset that will be used to train a model.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgHOrpca-7h-"
      },
      "source": [
        "cols_to_drop = []\n",
        "\n",
        "\"\"\"\n",
        "Check if column has any dissimilar data or not.\n",
        "If Column with no dissimilar data, add to cols_to_drop as it will be insignificant for model training.\n",
        "\"\"\"\n",
        "\n",
        "for (columnName, columnData) in mydata.iteritems():\n",
        "  if columnName == 'logged_in' or columnName == 'dst_host_same_srv_rate':\n",
        "    newdata = mydata[(mydata[columnName] != 1) | (mydata[columnName] != 1.00)]\n",
        "    if newdata.empty:\n",
        "      cols_to_drop.append(columnName)\n",
        "  else:\n",
        "    newdata = mydata[(mydata[columnName] != 0) | (mydata[columnName] != 0.00)]\n",
        "    if newdata.empty:\n",
        "      cols_to_drop.append(columnName)\n",
        "      \n",
        "print(cols_to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQQPNiq6l2Zh"
      },
      "source": [
        "### Drop Features\n",
        "\n",
        "The features we identified as futile are now dropped from the dataset we use to train the model. An original copy of the dataset is kept safe in a new variable. It is always smart to keep a copy of the original dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2T4cJOiFsUX"
      },
      "source": [
        "mydata_orig = mydata.copy()\n",
        "mydata.drop(columns=cols_to_drop, inplace=True)\n",
        "cols_to_drop = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENsaz_gW8n6e"
      },
      "source": [
        "### Visualize type of Attacks\n",
        "In the given dataframe, we will only be working with the select attack types from the dataset. We will be using the top 8 more frequent attacks available in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf6uG3bH9UlF"
      },
      "source": [
        "dd = mydata.groupby('label').size()\n",
        "dd.sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "140I6E8ykDmD"
      },
      "source": [
        "attacks = ['normal', 'neptune', 'smurf', 'back', 'satan', 'ipsweep', 'portsweep', 'warezclient']\n",
        "mydata = mydata[mydata['label'].isin(attacks)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2kWHcHfmQV1"
      },
      "source": [
        "### Identify missing values\n",
        "\n",
        "The code below helps us identify features in the dataset which have missing values in it. Machine Learning model needs to have a dataset with no missing values. Hence, it is a part of the data preprocessing to check if there are any missing values in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4lgJ5_fF17d"
      },
      "source": [
        "#finds column with missing values or null values \n",
        "def print_missing_values(data):\n",
        "  data_null = pd.DataFrame(len(data) - data.notnull().sum(), columns = ['Count'])\n",
        "  data_null = data_null[data_null['Count'] > 0].sort_values(by='Count', ascending=False)\n",
        "  data_null = data_null/len(data)*100\n",
        "  return data_null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbxvEWsJn2qb"
      },
      "source": [
        "### Missing values observation\n",
        "\n",
        "As we can see below, there seems to be no missing values in any feature in the dataset. Hence, we can skip the part where we identify median value of the row and replace with missing value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0is-_zyGPjR"
      },
      "source": [
        "print_missing_values(mydata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg3Wny84oEb9"
      },
      "source": [
        "### Numerical and Categorical Features\n",
        "\n",
        "It is necessary to split the features into numerical and categorical values before we feed the dataset to the model. All the integers are regarded as the numerical features and all the rest are categorized as categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vo90hwyIqwR"
      },
      "source": [
        "def categorize(data):\n",
        "  num_columns = []\n",
        "  cat_columns = []\n",
        "\n",
        "  #separate numerical and categorical features\n",
        "  for col in data.columns.values:\n",
        "    if data[col].dtypes == 'int64' or data[col].dtypes == 'float64':\n",
        "      num_columns += [col]\n",
        "    else: \n",
        "      cat_columns += [col]\n",
        "\n",
        "  return [cat_columns, num_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iia_8LEGZ2AB"
      },
      "source": [
        "categories = categorize(mydata)\n",
        "categorical_features = categories[0]\n",
        "numerical_features = categories[1]\n",
        "print(\"Categorical Features\", categorical_features)\n",
        "print(\"Numerical Features\", numerical_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GET9Fm2IpUbd"
      },
      "source": [
        "### Identify the type of labels\n",
        "\n",
        "Label is the column in the dateset which is what the model is going to predict using all the other features from the dataset. KDD dataset has multiple label hence making this multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zh5uLAUu2FR"
      },
      "source": [
        "attacks = set()\n",
        "for index, row in mydata.iterrows():\n",
        "  attacks.add(row['label'])\n",
        "print(attacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfjaiMmVs1Dl"
      },
      "source": [
        "### Import Scaler and label encoder\n",
        "\n",
        "Label Encoder helps encode the categorical features into numerical format. MinMaxScaler is one of the way of scaling and normalizing the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AslAZSDittdI"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXUPgN4WtvF6"
      },
      "source": [
        "### Utilizing Label Encoder\n",
        "Label Encoder converts the categorical features into numerical format so that the machine learning algorithm can understand it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu_vYIb9FQKN"
      },
      "source": [
        "def label_encode(data, categorical_features):\n",
        "  data_encoded = data.copy()\n",
        "\n",
        "  # Use Label Encoder for categorical columns (including target column)\n",
        "  for feature in categorical_features:\n",
        "      le = LabelEncoder()\n",
        "      le.fit(data_encoded[feature])\n",
        "      data_encoded[feature] = le.fit_transform(data_encoded[feature])\n",
        "      if feature == 'label':\n",
        "        le_name_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
        "\n",
        "  return (data_encoded, le_name_mapping)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1yqM0lwplnr"
      },
      "source": [
        "data_encoded, label_mapping = label_encode(mydata, categorical_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJAFCk-hAq-o"
      },
      "source": [
        "### label_mapping\n",
        "label_mapping variable is the hashmap which contains all the one-hot encoded numeric value and it's corresponding label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYxfqbiQtHo4"
      },
      "source": [
        "print(label_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdNaRPOaudiX"
      },
      "source": [
        "### Visualize the label\n",
        "\n",
        "As we can see in the result below, the label is converted into the numerical format from the categorical version for the model to understand and make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0jn2_PWv40N"
      },
      "source": [
        "labeled_attacks = set()\n",
        "for index, row in data_encoded.iterrows():\n",
        "  labeled_attacks.add(row['label'])\n",
        "print(labeled_attacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TiTpTM9msIM"
      },
      "source": [
        "data_encoded.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WfQZNW-uMfZ"
      },
      "source": [
        "### Utilizing Scaler\n",
        "\n",
        "Similary, we make use of the MinMaxScaler to scale and normalize the data and make it ready to use for the Machine Learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAlOwEHoaK_n"
      },
      "source": [
        "def scale_data(data, numerical_features):\n",
        "  data_encoded = data.copy()\n",
        "  for feature in numerical_features:\n",
        "      val = data_encoded[feature].values[:, np.newaxis]\n",
        "      mms = MinMaxScaler()\n",
        "      data_encoded[feature] = mms.fit_transform(val)\n",
        "      \n",
        "  data_encoded = data_encoded.astype(float)\n",
        "  return data_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYrqa2Sqqgtp"
      },
      "source": [
        "data_encoded = scale_data(data_encoded, numerical_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs4xs2nJaUcq"
      },
      "source": [
        "data_encoded.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrxhDVGk4uMd"
      },
      "source": [
        "print(label_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzdMD-B_jXXB"
      },
      "source": [
        "### What is Random Forest?\n",
        "Decision Trees are the fundamental part of the Random Forest Classifier. Random Forest consists of large number of individual decision trees that operate as an ensemble. The majority predictions from the individual decision trees is the ultimate prediction of the Random Forest Classifier.\n",
        "\n",
        "Understanding Random Forest\n",
        "\n",
        "https://towardsdatascience.com/understanding-random-forest-58381e0602d2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iSrz0HUvRmm"
      },
      "source": [
        "### RandomForest Classifier\n",
        "\n",
        "We use Random Forest Machine learning technique as suggested and experimented by one of the research paper. The paper found that the Random Forest works particularly best with the KDD dataset. \n",
        "\n",
        "Mohammad  Almseidin  et  al.  “Evaluation  of  MachineLearning  Algorithms  for  Intrusion  Detection  System”.In:CoRRabs/1801.02330  (2018).  arXiv:  1801.02330.URL: http://arxiv.org/abs/1801.02330."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ltY10fQIS2W"
      },
      "source": [
        "### Initilaizing Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQuU9MS4GoLk"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TpdfGkFweK9"
      },
      "source": [
        "### Model performance\n",
        "\n",
        "The function below evaluates the accuracy, precision, recall, and F1 score of the prediction made on the test dataset while also generating the confusion matrix for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6toRhJC5w-XV"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_curve, auc, precision_score, recall_score\n",
        "\n",
        "def get_model_performance(test_labels, predicted_labels):\n",
        "  accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "  matrix = (confusion_matrix(test_labels, predicted_labels)/test_labels.shape[0]) * 100\n",
        "  precision = precision_score(test_labels, predicted_labels, average='macro')\n",
        "  recall = recall_score(test_labels, predicted_labels, average='macro')\n",
        "  f1 = f1_score(test_labels, predicted_labels, average='macro')\n",
        "  return accuracy, matrix, precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay_W86rBxA-Q"
      },
      "source": [
        "### Plot Performance\n",
        "\n",
        "The function below helps plot the confusion matrix generated from the get_model_performance function above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbg0mTp5afej"
      },
      "source": [
        "def plot_model_performance(matrix):\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    sns.heatmap(matrix, annot=True, cmap='Blues', fmt='g')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(list(attacks))\n",
        "    ax.yaxis.set_ticklabels(list(attacks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y6AWw6qHwzO"
      },
      "source": [
        "## SECTION I \n",
        "### Using Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNx1Q0XB_egQ"
      },
      "source": [
        "### Create Features and Labels\n",
        "labels contains all the labels from the dataset and features contains the dataframe except the values from label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKP1f7_KGoS7"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "data_encoded = shuffle(data_encoded)\n",
        "labels = data_encoded['label']\n",
        "features = data_encoded.drop('label', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3MflRnx_YiI"
      },
      "source": [
        "### Train and Test Data Split\n",
        "\n",
        "It is absolutely necessary to split the data into training, testing, and validation to make sure Machine Learning algorithms are learning well and can make predictions as accurately as possible. Here we use train_test_split to split 80% of the data as the train, 10% as the test and the rest 10% as the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rHsggboGoQX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "train_features, rem_features, train_labels, rem_labels = train_test_split(features, labels, train_size=0.8, shuffle=True)\n",
        "valid_features, test_features, valid_labels, test_labels = train_test_split(rem_features, rem_labels, test_size=0.5, shuffle=True)\n",
        "\n",
        "print(\"Train Dataset Feature Shape: \")\n",
        "print(train_features.shape)\n",
        "print(\"Test Dataset Feature Shape: \")\n",
        "print(test_features.shape)\n",
        "print(\"Valid Dataset Feature Shape: \")\n",
        "print(valid_features.shape)\n",
        "print(\"Train Dataset label Shape: \")\n",
        "print(train_labels.shape)\n",
        "print(\"Test Dataset label Shape: \")\n",
        "print(test_labels.shape)\n",
        "print(\"Valid Dataset label Shape: \")\n",
        "print(valid_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAGwvjxQ_zFR"
      },
      "source": [
        "### Visualize labels \n",
        "As we  can see below, the labels present in the dataframe only belong to select few types of attack. The proportion of the attacks present in the dataset is not uniform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4DemcujGoN9"
      },
      "source": [
        "lst = []\n",
        "for i in range(valid_labels.shape[0]):\n",
        "    lst.append(int(valid_labels.iloc[i]))\n",
        "\n",
        "print(\"Labels: \", lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilUJ3oEnu_NU"
      },
      "source": [
        "print(label_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Un8g5apAnpd"
      },
      "source": [
        "### Fit model\n",
        "Fit the model with the features and labels dataframe created from the train_test_split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RlRj8LMGoHD"
      },
      "source": [
        "rf.fit(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhAa2tndI-iS"
      },
      "source": [
        "### Testing\n",
        "\n",
        "The test features and train features are used to predict the labels and test the performance of the Random Forest model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHRGOUz4I-iT"
      },
      "source": [
        "The accuracy of the model using the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4LrShnbI-iT"
      },
      "source": [
        "train_pred_labels = rf.predict(train_features)\n",
        "accuracy, matrix, precision, recall, f1 = get_model_performance(train_labels, train_pred_labels)\n",
        "print(\"The accuracy of the model: \", accuracy)\n",
        "print(\"The precision of the model: \", precision)\n",
        "print(\"The recall of the model: \", recall)\n",
        "print(\"The f1 score of the model: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJwKLCQkI-iT"
      },
      "source": [
        "The accuracy of the model using the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wEX2siKI-iT"
      },
      "source": [
        "test_pred_labels = rf.predict(test_features)\n",
        "accuracy, matrix, precision, recall, f1 = get_model_performance(test_labels, test_pred_labels)\n",
        "print(\"The accuracy of the model: \", accuracy)\n",
        "print(\"The precision of the model: \", precision)\n",
        "print(\"The recall of the model: \", recall)\n",
        "print(\"The f1 score of the model: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA6wlufeJK1Q"
      },
      "source": [
        "The training accuracy and test accuracy doesn't seem to have a lot of difference. Hence, it shows that the model was not overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIBg4p9uJK1V"
      },
      "source": [
        "plot_model_performance(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7DtRlqLJK1V"
      },
      "source": [
        "### Randomly selected instances for validation\n",
        "The code below creates a list of lists named 'data' consisting of randomly selected instances from the validation dataset, where only features are included. It also creates a list of it's corresponding true labels named true_labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6_FpPRCJK1V"
      },
      "source": [
        "import random\n",
        "data = []\n",
        "true_labels = []\n",
        "\n",
        "for i in range(10):\n",
        "  temp = random.randint(0, valid_features.shape[0])\n",
        "  data.append(valid_features.iloc[temp].tolist())\n",
        "  true_labels.append(valid_labels.iloc[temp])\n",
        "\n",
        "for index, ele in enumerate(true_labels):\n",
        "  true_labels[index] = label_mapping[int(ele)]\n",
        "\n",
        "print(data)\n",
        "print(true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIvnJA4FJK1V"
      },
      "source": [
        "### Create Dataframe\n",
        "Create a pandas dataframe called new_data out of the list of lists of instances generated in the code cell above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpJZXGqJK1V"
      },
      "source": [
        "new_data = pd.DataFrame(data)\n",
        "print(new_data)\n",
        "new_data.columns = valid_features.columns.tolist()\n",
        "new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtuDUSvgJK1V"
      },
      "source": [
        "### Validate results\n",
        "The randomly selected instances of data not used in the training and testing are used to make preidctions of it's label. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SdbcYOKJK1V"
      },
      "source": [
        "features_new = np.array(new_data)\n",
        "pred_labels = rf.predict(features_new)\n",
        "pred_labels = pred_labels.tolist()\n",
        "\n",
        "for index, ele in enumerate(pred_labels):\n",
        "  temp = label_mapping[int(ele)]\n",
        "  pred_labels[index] = label_mapping[int(ele)]\n",
        "\n",
        "print(\"True labels: \", true_labels)\n",
        "print(\"Pred labels: \", pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ1TINFJIzBe"
      },
      "source": [
        "## SECTION II\n",
        "### Using balanced Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEcp7SZIC5GK"
      },
      "source": [
        "### Create Features and Labels\n",
        "Separate features and labels into two different dataset to create Synthetic data and further split into train and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5RpombMzy_3"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "data_encoded = shuffle(data_encoded)\n",
        "features_SMOTE = data_encoded.iloc[:, data_encoded.columns != 'label']\n",
        "labels_SMOTE = data_encoded.iloc[:, data_encoded.columns == 'label']\n",
        "\n",
        "X_SMOTE = features.to_numpy()\n",
        "y_SMOTE = labels.to_numpy()\n",
        "counter_orig = Counter(y_SMOTE)\n",
        "print(y_SMOTE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWRKguCzED_E"
      },
      "source": [
        "### Visualize count of Attack types\n",
        "The bar graph below shows the number of instances for each attack type in the original dataset before creating synthetic instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x20TWcFjED_E"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "attack_types = []\n",
        "for c in counter_orig.keys():\n",
        "  attack_types.append(label_mapping[c])\n",
        "  \n",
        "pyplot.figure(figsize=(8,7))\n",
        "pyplot.bar(attack_types, counter_orig.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3kSj9c_CIti"
      },
      "source": [
        "### SMOTE\n",
        "Imbalanced classification involves developing predicitve models on classification datasets that have a class inbalance. Synthetic Minority Oversampling Technique, or SMOTE is an approach to address imbalanced dataset where minority class is oversampled. It creates new synthetic instances according to the neighbourhood of each example of the minority class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dGgPu9UOOZD"
      },
      "source": [
        "strategy_over = {0:201862, 1:187396, 2:239604, 4:178387, 5:195267, 3:216522, 7:173021}\n",
        "strategy_under = {6:242063}\n",
        "over = SMOTE(sampling_strategy = strategy_over)\n",
        "under = RandomUnderSampler(sampling_strategy = strategy_under)\n",
        "\n",
        "steps = [('o', over),('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "X_SMOTE, y_SMOTE = pipeline.fit_resample(X_SMOTE, y_SMOTE)\n",
        "\n",
        "counter = Counter(y_SMOTE)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7mNdworDInj"
      },
      "source": [
        "### Visualize count of Attack types after SMOTE\n",
        "The bar graph below shows the number of instances for each attack type in the dataset after creating synthetic instances using SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cn8CPGo6Q4c"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "attack_types = []\n",
        "for c in counter.keys():\n",
        "  attack_types.append(label_mapping[c])\n",
        "\n",
        "pyplot.figure(figsize=(8,7))  \n",
        "pyplot.bar(attack_types, counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nD4F_rA_fGg"
      },
      "source": [
        "X_SMOTE = pd.DataFrame(X_SMOTE, columns=features_SMOTE.columns)\n",
        "y_SMOTE = pd.DataFrame(y_SMOTE, columns=labels_SMOTE.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Otmyagu-bE"
      },
      "source": [
        "### Train and Test Data Split\n",
        "\n",
        "It is absolutely necessary to split the data into training, testing, and validation to make sure Machine Learning algorithms are learning well and can make predictions as accurately as possible. Here we use train_test_split to split 80% of the data as the train, 10% as the test and the rest 10% as the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lMoNzeCaYeC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "train_features_SMOTE, rem_features, train_labels_SMOTE, rem_labels = train_test_split(X_SMOTE, y_SMOTE, train_size=0.8, shuffle=True)\n",
        "valid_features_SMOTE, test_features_SMOTE, valid_labels_SMOTE, test_labels_SMOTE = train_test_split(rem_features, rem_labels, test_size=0.5, shuffle=True)\n",
        "\n",
        "print(\"Train Dataset Feature Shape: \")\n",
        "print(train_features_SMOTE.shape)\n",
        "print(\"Test Dataset Feature Shape: \")\n",
        "print(test_features_SMOTE.shape)\n",
        "print(\"Valid Dataset Feature Shape: \")\n",
        "print(valid_features_SMOTE.shape)\n",
        "print(\"Train Dataset label Shape: \")\n",
        "print(train_labels_SMOTE.shape)\n",
        "print(\"Test Dataset label Shape: \")\n",
        "print(test_labels_SMOTE.shape)\n",
        "print(\"Valid Dataset label Shape: \")\n",
        "print(valid_labels_SMOTE.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U82XMP_aRBA-"
      },
      "source": [
        "print(label_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCwXK2JKE3ub"
      },
      "source": [
        "### Visualize labels \n",
        "As we  can see below, the labels present in the dataframe belong to various types of attack. The proportion of the attacks present in the dataset are more uniform after creating synthetic data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8xdz80Y69-i"
      },
      "source": [
        "lst = []\n",
        "for i in range(valid_labels_SMOTE.shape[0]):\n",
        "    lst.append(int(valid_labels_SMOTE.iloc[i]))\n",
        "\n",
        "print(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9XL0lmr4Sje"
      },
      "source": [
        "print(label_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz24GuADFGGt"
      },
      "source": [
        "### Fit model\n",
        "Fit the model with the features and labels dataframe created from the train_test_split from the new dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPWBeg0ptzgQ"
      },
      "source": [
        "rf.fit(train_features_SMOTE, train_labels_SMOTE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRTHSJGAwzuc"
      },
      "source": [
        "### Testing\n",
        "\n",
        "The test features are used to predict the labels and  test the performance of the Random Forest model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAagrQzWaGNw"
      },
      "source": [
        "The accuracy of the model using the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie2-XncJ682o"
      },
      "source": [
        "train_pred_labels_SMOTE = rf.predict(train_features_SMOTE)\n",
        "accuracy, matrix, precision, recall, f1 = get_model_performance(train_labels_SMOTE, train_pred_labels_SMOTE)\n",
        "print(\"The accuracy of the model: \", accuracy)\n",
        "print(\"The precision of the model: \", precision)\n",
        "print(\"The recall of the model: \", recall)\n",
        "print(\"The f1 score of the model: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yDwEOHAvxra"
      },
      "source": [
        "The accuracy of the model using the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_dPEMCvusdz"
      },
      "source": [
        "test_pred_labels_SMOTE = rf.predict(test_features_SMOTE)\n",
        "accuracy, matrix, precision, recall, f1 = get_model_performance(test_labels_SMOTE, test_pred_labels_SMOTE)\n",
        "print(\"The accuracy of the model: \", accuracy)\n",
        "print(\"The precision of the model: \", precision)\n",
        "print(\"The recall of the model: \", recall)\n",
        "print(\"The f1 score of the model: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKeIuSEFv09l"
      },
      "source": [
        "The training accuracy and test accuracy doesn't seem to have a lot of difference. Hence, it shows that the model was not overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE-4M-e738DI"
      },
      "source": [
        "plot_model_performance(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMXGdhypR4-Q"
      },
      "source": [
        "print(valid_features_SMOTE.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3KazUwMw2A3"
      },
      "source": [
        "### Randomly selected instances for validation\n",
        "The code below creates a list of lists named 'data' consisting of randomly selected instances from the validation dataset, where only features are included. It also creates a list of it's corresponding true labels named true_labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F7EdjvLRvaS"
      },
      "source": [
        "import random\n",
        "data = []\n",
        "true_labels_SMOTE = []\n",
        "\n",
        "for i in range(10):\n",
        "  temp = random.randint(0, valid_features_SMOTE.shape[0])\n",
        "  data.append(valid_features_SMOTE.iloc[temp].tolist())\n",
        "  true_labels_SMOTE.append(valid_labels_SMOTE.iloc[temp])\n",
        "\n",
        "for index, ele in enumerate(true_labels_SMOTE):\n",
        "  true_labels_SMOTE[index] = label_mapping[int(ele)]\n",
        "\n",
        "print(data)\n",
        "print(true_labels_SMOTE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p1vpBcqxhF3"
      },
      "source": [
        "### Create Dataframe\n",
        "Create a pandas dataframe called new_data out of the list of lists of instances generated in the code cell above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NIl-5KNPU7r"
      },
      "source": [
        "new_data = pd.DataFrame(data)\n",
        "print(new_data)\n",
        "new_data.columns = valid_features_SMOTE.columns.tolist()\n",
        "new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ReTb7Rtxtgs"
      },
      "source": [
        "### Validate results\n",
        "The randomly selected instances of data not used in the training and testing are used to make preidctions of it's label. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuIMghrDQJiS"
      },
      "source": [
        "features_new_SMOTE = np.array(new_data)\n",
        "pred_labels_SMOTE = rf.predict(features_new_SMOTE)\n",
        "pred_labels_SMOTE = pred_labels_SMOTE.tolist()\n",
        "\n",
        "for index, ele in enumerate(pred_labels_SMOTE):\n",
        "  temp = label_mapping[int(ele)]\n",
        "  pred_labels_SMOTE[index] = label_mapping[int(ele)]\n",
        "\n",
        "print(\"True labels: \", true_labels_SMOTE)\n",
        "print(\"Pred labels: \", pred_labels_SMOTE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}